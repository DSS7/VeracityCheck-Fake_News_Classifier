{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "067dc227",
   "metadata": {},
   "source": [
    "### Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e52a6a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\37789\\onedrive\\documents\\github\\veracitycheck-fake_news_classifier\\venv\\lib\\site-packages (3.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\37789\\onedrive\\documents\\github\\veracitycheck-fake_news_classifier\\venv\\lib\\site-packages (from xgboost) (2.3.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\37789\\onedrive\\documents\\github\\veracitycheck-fake_news_classifier\\venv\\lib\\site-packages (from xgboost) (1.16.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\37789\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\37789\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\37789\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "!pip install xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Download stopwords if not already\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Download WordNet if not already\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fdd0df44",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../Dataset/LIAR DATASET/train.tsv\", sep='\\t', header=None)\n",
    "valid_df = pd.read_csv(\"../Dataset/LIAR DATASET/valid.tsv\", sep='\\t', header=None)\n",
    "test_df  = pd.read_csv(\"../Dataset/LIAR DATASET/test.tsv\", sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d124f4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"id\", \"label\", \"statement\", \"subject\", \"speaker\", \"job_title\", \n",
    "    \"state\", \"party\", \"barely_true\", \"false\", \"half_true\", \n",
    "    \"mostly_true\", \"pants_fire\", \"context\"\n",
    "]\n",
    "\n",
    "train_df.columns = columns\n",
    "valid_df.columns = columns\n",
    "test_df.columns  = columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7fffd2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>job_title</th>\n",
       "      <th>state</th>\n",
       "      <th>party</th>\n",
       "      <th>barely_true</th>\n",
       "      <th>false</th>\n",
       "      <th>half_true</th>\n",
       "      <th>mostly_true</th>\n",
       "      <th>pants_fire</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a mailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10540.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>State delegate</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a floor speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1123.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>blog-posting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>a news release</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9028.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>economy,jobs</td>\n",
       "      <td>charlie-crist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Florida</td>\n",
       "      <td>democrat</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>an interview on CNN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        label                                          statement  \\\n",
       "0   2635.json        false  Says the Annies List political group supports ...   \n",
       "1  10540.json    half-true  When did the decline of coal start? It started...   \n",
       "2    324.json  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3   1123.json        false  Health care reform legislation is likely to ma...   \n",
       "4   9028.json    half-true  The economic turnaround started at the end of ...   \n",
       "\n",
       "                              subject         speaker             job_title  \\\n",
       "0                            abortion    dwayne-bohac  State representative   \n",
       "1  energy,history,job-accomplishments  scott-surovell        State delegate   \n",
       "2                      foreign-policy    barack-obama             President   \n",
       "3                         health-care    blog-posting                   NaN   \n",
       "4                        economy,jobs   charlie-crist                   NaN   \n",
       "\n",
       "      state       party  barely_true  false  half_true  mostly_true  \\\n",
       "0     Texas  republican          0.0    1.0        0.0          0.0   \n",
       "1  Virginia    democrat          0.0    0.0        1.0          1.0   \n",
       "2  Illinois    democrat         70.0   71.0      160.0        163.0   \n",
       "3       NaN        none          7.0   19.0        3.0          5.0   \n",
       "4   Florida    democrat         15.0    9.0       20.0         19.0   \n",
       "\n",
       "   pants_fire              context  \n",
       "0         0.0             a mailer  \n",
       "1         0.0      a floor speech.  \n",
       "2         9.0               Denver  \n",
       "3        44.0       a news release  \n",
       "4         2.0  an interview on CNN  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First few rows\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2fcb74b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Train  Validation  Test\n",
      "id               0           0     0\n",
      "label            0           0     0\n",
      "statement        0           0     0\n",
      "subject          2           0     0\n",
      "speaker          2           0     0\n",
      "job_title     2898         345   325\n",
      "state         2210         279   262\n",
      "party            2           0     0\n",
      "barely_true      2           0     0\n",
      "false            2           0     0\n",
      "half_true        2           0     0\n",
      "mostly_true      2           0     0\n",
      "pants_fire       2           0     0\n",
      "context        102          12    17\n"
     ]
    }
   ],
   "source": [
    "# Combine missing values side by side\n",
    "missing_summary = pd.concat([\n",
    "    train_df.isnull().sum().rename('Train'),\n",
    "    valid_df.isnull().sum().rename('Validation'),\n",
    "    test_df.isnull().sum().rename('Test')\n",
    "], axis=1)\n",
    "\n",
    "print(missing_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "512ac6a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "half-true      2114\n",
       "false          1995\n",
       "mostly-true    1962\n",
       "true           1676\n",
       "barely-true    1654\n",
       "pants-fire      839\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class distribution\n",
    "train_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9e893bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 10240\n",
      "Validation: 1284\n",
      "Test: 1267\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\", len(train_df))\n",
    "print(\"Validation:\", len(valid_df))\n",
    "print(\"Test:\", len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dc00ff4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10240 entries, 0 to 10239\n",
      "Data columns (total 14 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   id           10240 non-null  object \n",
      " 1   label        10240 non-null  object \n",
      " 2   statement    10240 non-null  object \n",
      " 3   subject      10238 non-null  object \n",
      " 4   speaker      10238 non-null  object \n",
      " 5   job_title    7342 non-null   object \n",
      " 6   state        8030 non-null   object \n",
      " 7   party        10238 non-null  object \n",
      " 8   barely_true  10238 non-null  float64\n",
      " 9   false        10238 non-null  float64\n",
      " 10  half_true    10238 non-null  float64\n",
      " 11  mostly_true  10238 non-null  float64\n",
      " 12  pants_fire   10238 non-null  float64\n",
      " 13  context      10138 non-null  object \n",
      "dtypes: float64(5), object(9)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f3e591ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAHqCAYAAACZcdjsAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAASwFJREFUeJzt3Qd0VNXaxvE3tFATpCUgHZTeEUSKIEgERGn3qlQV4YKACooYpQY1gkoRuSBXiigIFgRFL70KoQXpRRCkSFVKBCQhJN969/1mnEkmAXKSTPv/1pqVzDknkz2ZTHKes/e7d0BiYmKiAAAAAIAFWax8MQAAAAAoggUAAAAAywgWAAAAACwjWAAAAACwjGABAAAAwDKCBQAAAADLCBYAAAAALCNYAAAAALCMYAEAAADAMoIFADj49ddfJSAgQN577710e8w1a9aYx9SP6W3kyJHmsTND06ZNzS3p8/rqq68y5fs//fTTUrp0aXHX78SsWbPEm2ib9fcDADILwQKA19MTPj2J2rZtm/jC87DdcubMKcWKFZOwsDD54IMP5M8//0yX73Pq1Clzwrljxw7xNJ7ctox4jVO6uSNA3Y7vvvtOHnzwQSlSpIjkzp1bypYtK//85z9lyZIlaXq8t99+WxYuXJju7QTgHtnc9H0BACmIiIiQMmXKyI0bN+TMmTOmZ+Cll16ScePGybfffivVq1e3Hzt06FB57bXX7vjkfdSoUebktWbNmrf9dcuWLZOMllrb/vOf/0hCQoJktlKlSslff/0l2bNnt/xYTZo0kU8//dRp23PPPSf16tWT3r1727flzZvX8vfSNmfLln7/5rUXb/DgwSZYhIeHm2Bx+PBhWbFihcybN08eeeSRNAWLTp06Sbt27dKtnQDch2ABAB6mVatWUrduXft9PYlbtWqVPProo/LYY4/J/v37JVeuXGafnjim58mjK9euXTMnkTly5BB3So8T+7Sw9R6lB73CrzdHffr0Mdu6du2a4tfFx8ebUHUnr0F6tdn2/UePHi0PP/ywy4B57ty5dPteALwXQ6EA+IW4uDgZPny41KlTR4KDgyVPnjzSuHFjWb16dYpfM378eHO1Wk/i9Srtnj17kh1z4MABc8W1QIEC5kROA4H2KqS3hx56SIYNGybHjh2Tzz77LNUai+XLl0ujRo0kf/785sp3hQoV5PXXXzf7tPfjvvvuM58/88wz9qE3tvoBraGoWrWqREdHm6vrGihsX5u0xsLm5s2b5pjQ0FDzc9Xwc+LECadjtAdCaySScnzMW7XNVY3F1atX5eWXX5YSJUpIYGCgea56ZT0xMdHpOH2c/v37m2E3+vz02CpVqtzWEB5XNRbaFv3Z/vbbb+Zqu35euHBheeWVV8zPI73qfCZMmCDlypUz7d23b98d/R4nrbGw/a5oL4O2X38/9DH0Z63hMTW///67xMTESMOGDV3u16FRjmJjY2XEiBFSvnx503Z9fV599VWz3bF9+vp98skn9tfa1e8IAO9BjwUAv6AnRR9//LE89dRT0qtXL1OvMH36dFO/sGXLlmTDbmbPnm2O6devn1y/fl0mTpxoTu53794tISEh5pi9e/eaE627777bDEfSk7wvvvjCnGh+/fXX0r59+3R9Dt26dTMn8HrFWJ+DK9om7dnQ4VI6pEpP6vREcsOGDWZ/pUqVzHY9OdWhN3pSqh544AH7Y/zxxx+m1+TJJ580V9Ftzzclb731ljkpHDJkiLlyrSfDLVq0MHUStp6V23E7bXOk4UFDjJ5U9+zZ07yGS5cuNcN19IRfg6GjH3/8URYsWCDPP/+85MuXz9StdOzYUY4fPy4FCxaUO6UBQn9/6tevb0KADgl6//33TRDo27evWDVz5kzzu6c/C30dNbze6e+xK1oToUPtIiMjZfv27ebxNBiMGTMmxa/R/fpaao3FgAEDTFtSoj0r+rroz1vbrq+rvm/09fj555/tNRU6JCzpMDD92QHwYokA4OVmzpypl6cTt27dmuIx8fHxibGxsU7bLl68mBgSEpL47LPP2rcdPXrUPFauXLkST548ad++efNms33gwIH2bc2bN0+sVq1a4vXr1+3bEhISEh944IHEe+65x75t9erV5mv1o9XnERwcnFirVi37/REjRpivsRk/fry5f/78+RQfQx9fj9Hvl9SDDz5o9k2dOtXlPr0lfV533313YkxMjH37F198YbZPnDjRvq1UqVKJPXr0uOVjptY2/Xp9HJuFCxeaY998802n4zp16pQYEBCQePjwYfs2PS5HjhxO23bu3Gm2T5o0KTE1tt8JxzZpW3RbRESE07H62tSpUyfxTuTJk8fpZ2P7fkFBQYnnzp1L0++x7Tnr70fS35Wkx7Vv3z6xYMGCt2zn8OHDzddre1u1apX41ltvJUZHRyc77tNPP03MkiVL4vr165226++Ufv2GDRtSfO4AvBtDoQD4haxZs9rHp+sV1QsXLphx4zp0Sa/aJqW9DtoTYaNXVfXK9A8//GDu69dr3YNe/dWrxjpURG96tV+vHh86dMhcNU9vOuQmtdmhdHiLWrRoUZoLnfXquA6PuV3du3c3PQA2OjSsaNGi9p9VRtHH19f1hRdecNquQ6P0vPq///2v03btRXG8Iq69OkFBQXLkyJE0t0HrIxxpL4uVx3OkvSk6vMrK7/Httll/b7U3JDVaVD937lypVauW6Rl64403zJCs2rVrm7ofmy+//NL0UlSsWNH+vtCb9vip1IYfAvBuBAsAfkPHcuvJpNZC6NAXPWn7/vvv5fLly8mOveeee5Jtu/fee834d6XDi/TkVese9HEcbzq2PKMKWq9cueJ0Ep/UE088YYZn6RATHcKkw5l0eNadhAwNVHdSJJz0Z6XDonRsve1nlVG03kSn403689CTWtt+RyVLlkz2GHfddZdcvHgxTd9ff4+SnvhbebykdLiS1d9jV5L+HLTN6nbarUOw1q9fb47VIXmdO3eWn376Sdq2bWuGbSkN1TokL+n7Qt8/ikJvwHdRYwHAL2jBsxaGak+EjsHXMeN69VfHmf/yyy93/Hi2E3Ut1tUeClf05Do9nTx50pw8pva4Og5+3bp15qqwnmxqcfL8+fPN1WI9EdTnfCt3Uhdxu1JaxE/rFG6nTekhpe+TtNDb6uOlF1evQ3r8HqfHz0F7enSGKL3pbF0adjZv3mwmOdD3RrVq1cz0yK5oITcA30SwAOAXdHVondJTi3cdT3JtvQtJ6VXXpLTw1DYrkW3KUD2p0iE2mcG2/kFKQcYmS5Ys0rx5c3PTkztdK0CHrWjY0Lam90rdSX9WeoKqPTqO623oVfFLly4l+1rtVXCcfvVO2qYzdmnBtA4Nc+y10Jm6bPv9/fc4M+gwLA0Wp0+fNvd1uNnOnTvN79+tXs/MWjUeQOZgKBQAv2C7Sut4VVavsEZFRbk8XmeucayR0Bl39HidLUnplWKdJvWjjz6yn1A5On/+fLq2X+s5dB0BHR7TpUuXFI/TMfdJ2WYKsk31qbNXKVcn+mlhm0HL8eRXfya2n5XtZHPTpk1mulSbxYsXJ5uW9k7a1rp1a9Pj8eGHHzpt19mH9ITV8fv76+9xetHpaFP6HrZaFp3qV2ndkb53dEFDV4v26RSzjq93ev0eAnA/eiwA+IwZM2a4XJfgxRdfNFOw6lVenQK2TZs2cvToUZk6dapUrlzZ1C0kpcONdC0InTZUT8h1ClUdz65z8dtMnjzZHKPDPnTqT72SfPbsWXMCpsOW9KptWuiJml5116JcfTwNFbo2hV6B1zUyUlv4TKdr1aFQ+hz1eB3P/u9//1uKFy9u2mo7ydcib33+eqVfT+60MD2lMf23olOP6mNrwbe2V39W+vNznBJXaz40cOjqzHriqcN2dFhP0ulF76RtOq6/WbNmpjdG6zlq1Khhhntp4bquVO6LU5fe6e9xegYLnfb3/vvvN6+hDmfSQKABXGsudGiWFnXbpkXWuh4tEtdeMq350QCov9O6XQu/bQtAavG39jppz5rWy+jrrK83AO9EsADgM6ZMmeJyu45J19uZM2dMD4Oe2OiJmJ7Y6gw2ujCbq5mOdEiRniTrybnOCqVXxnW2Ixt9jG3btpnZcnTxNJ1ZR3sy9ARL12JIK9vXagG1nrRrcNF26Il7aoXbStcP0JNsDVk6E0+hQoXMuHdtoy6Gpmxj4nVFbz350wCjayakNVjo2hq7du0y4/y150KHwGiY0cX1bHT4lq7xoCeQetKvJ5baY6EzODm6k7bp66NBS39eWkeix+lQtXfffTfZ4/qKO/09Ti8a9rQHQut29OesbdDeE+2l0J+348xc+rpo4NCeI+3N+uabb8zvggZvDfm2Im6lvw+6hsXQoUNNb0aPHj0IFoAXC9A5Z93dCAAAAADejRoLAAAAAJYRLAAAAABYRrAAAAAAYBnBAgAAAIBlBAsAAAAAlhEsAAAAAFjGOha3ISEhQU6dOmXmj9fVXAEAAAB/kJiYaNYo0kUsdZ2a1BAsboOGCl1lFAAAAPBHJ06ckOLFi6d6DMHiNthWutUfaFBQkLubAwAAAGSKmJgYc4Hddj6cGoLFbbANf9JQQbAAAACAvwm4jXIAircBAAAAWEawAAAAAGAZwQIAAACAZQQLAAAAAJYRLAAAAABYRrAAAAAAYBnBAgAAAIBlBAsAAAAAlhEsAAAAAFhGsAAAAABgGcECAAAAgGUECwAAAACWESwAAAAAWJbN+kMgI5V+7XvxF7++08bdTQAAAEAa0WMBAAAAwDKCBQAAAADLCBYAAAAALCNYAAAAALCMYAEAAADAMoIFAAAAAMsIFgAAAAAsI1gAAAAAsIxgAQAAAMAyggUAAAAAywgWAAAAACwjWAAAAADw7mARGRkp9913n+TLl0+KFCki7dq1k4MHDzodc/36denXr58ULFhQ8ubNKx07dpSzZ886HXP8+HFp06aN5M6d2zzO4MGDJT4+3umYNWvWSO3atSUwMFDKly8vs2bNypTnCAAAAPgDtwaLtWvXmtCwadMmWb58udy4cUNatmwpV69etR8zcOBA+e677+TLL780x586dUo6dOhg33/z5k0TKuLi4mTjxo3yySefmNAwfPhw+zFHjx41xzRr1kx27NghL730kjz33HOydOnSTH/OAAAAgC8KSExMTBQPcf78edPjoAGiSZMmcvnyZSlcuLDMnTtXOnXqZI45cOCAVKpUSaKiouT++++X//73v/Loo4+awBESEmKOmTp1qgwZMsQ8Xo4cOczn33//vezZs8f+vZ588km5dOmSLFmy5JbtiomJkeDgYNOeoKAgyUylX/te/MWv77RxdxMAAACQxvNgj6qx0AarAgUKmI/R0dGmF6NFixb2YypWrCglS5Y0wULpx2rVqtlDhQoLCzM/hL1799qPcXwM2zG2xwAAAABgTTbxEAkJCWaIUsOGDaVq1apm25kzZ0yPQ/78+Z2O1RCh+2zHOIYK237bvtSO0fDx119/Sa5cuZz2xcbGmpuNHgcAAADAC3ostNZChyrNmzfP3U0xReXa5WO7lShRwt1NAgAAADyaR/RY9O/fXxYvXizr1q2T4sWL27eHhoaaomythXDstdBZoXSf7ZgtW7Y4PZ5t1ijHY5LOJKX3dZxY0t4KFR4eLoMGDXLqsSBcIL1QNwMAAHyRW3sstG5cQ8U333wjq1atkjJlyjjtr1OnjmTPnl1Wrlxp36bT0er0sg0aNDD39ePu3bvl3Llz9mN0hikNDZUrV7Yf4/gYtmNsj5GUTkmrX+94AwAAAOChPRY6/ElnfFq0aJFZy8JWE6HDj7QnQT/27NnT9B5oQbee4A8YMMAEAp0RSun0tBogunXrJmPHjjWPMXToUPPYGhBUnz595MMPP5RXX31Vnn32WRNivvjiCzNTFAAAAAAv77GYMmWKmQmqadOmUrRoUftt/vz59mPGjx9vppPVhfF0Clod1rRgwQL7/qxZs5phVPpRA0fXrl2le/fuEhERYT9Ge0I0RGgvRY0aNeT999+Xjz/+2MwMBQAAAMDH1rHwVKxjkTn8ZTw+rykAAPDF82CPKN4GAG9HYAQA+DuPmW4WAAAAgPciWAAAAACwjGABAAAAwDKCBQAAAADLCBYAAAAALCNYAAAAALCMYAEAAADAMoIFAAAAAMsIFgAAAAAsI1gAAAAAsIxgAQAAAMAyggUAAAAAywgWAAAAACwjWAAAAACwjGABAAAAwDKCBQAAAADLCBYAAAAALCNYAAAAALCMYAEAAADAMoIFAAAAAMsIFgAAAAAsI1gAAAAAsIxgAQAAAMAyggUAAAAAywgWAAAAACwjWAAAAADw7mCxbt06adu2rRQrVkwCAgJk4cKFTvt1m6vbu+++az+mdOnSyfa/8847To+za9cuady4seTMmVNKlCghY8eOzbTnCAAAAPgDtwaLq1evSo0aNWTy5Mku958+fdrpNmPGDBMcOnbs6HRcRESE03EDBgyw74uJiZGWLVtKqVKlJDo62oSSkSNHyrRp0zL8+QEAAAD+Ips7v3mrVq3MLSWhoaFO9xctWiTNmjWTsmXLOm3Ply9fsmNt5syZI3FxcSaU5MiRQ6pUqSI7duyQcePGSe/evdPpmQAAAAD+zWtqLM6ePSvff/+99OzZM9k+HfpUsGBBqVWrlumRiI+Pt++LioqSJk2amFBhExYWJgcPHpSLFy9mWvsBAAAAX+bWHos78cknn5ieiQ4dOjhtf+GFF6R27dpSoEAB2bhxo4SHh5vhUNojoc6cOSNlypRx+pqQkBD7vrvuuivZ94qNjTU3x+FUAAAAAHwgWOhQpi5dupgCbEeDBg2yf169enXTM/Gvf/1LIiMjJTAwME3fS7921KhRltsMAAAA+AuvGAq1fv16M3Tpueeeu+Wx9evXN0Ohfv31V3Nfay90GJUj2/2U6jK01+Py5cv224kTJ9LleQAAAAC+yiuCxfTp06VOnTpmBqlb0cLsLFmySJEiRcz9Bg0amGltb9y4YT9m+fLlUqFCBZfDoJT2dAQFBTndAAAAAHhosLhy5YoJAnpTR48eNZ8fP37cqb7hyy+/dNlboYXZEyZMkJ07d8qRI0fMDFADBw6Url272kND586dzfAoLfreu3evzJ8/XyZOnOg0hAoAAACAF9dYbNu2zUwfa2M72e/Ro4fMmjXLfD5v3jxJTEyUp556ymXPgu7XdSm02FqLtDVYOIaG4OBgWbZsmfTr18/0ehQqVEiGDx/OVLMAAACArwSLpk2bmtCQGg0AKYUAnQ1q06ZNt/w+WtStdRoAAAAA/LjGAgAAAIBnI1gAAAAAsIxgAQAAAMAyggUAAAAAywgWAAAAALx7VigAADxZ6de+F3/w6ztt3N0EAD6AHgsAAAAAlhEsAAAAAFhGsAAAAABgGTUWAADAb/hL3YyidgaZjR4LAAAAAJYRLAAAAABYRrAAAAAAYBnBAgAAAIBlBAsAAAAAlhEsAAAAAFhGsAAAAABgGcECAAAAgGUECwAAAACWESwAAAAAWEawAAAAAGAZwQIAAACAZQQLAAAAAJYRLAAAAABYRrAAAAAAYBnBAgAAAIBlBAsAAAAAlhEsAAAAAHh3sFi3bp20bdtWihUrJgEBAbJw4UKn/U8//bTZ7nh75JFHnI65cOGCdOnSRYKCgiR//vzSs2dPuXLlitMxu3btksaNG0vOnDmlRIkSMnbs2Ex5fgAAAIC/cGuwuHr1qtSoUUMmT56c4jEaJE6fPm2/ff755077NVTs3btXli9fLosXLzZhpXfv3vb9MTEx0rJlSylVqpRER0fLu+++KyNHjpRp06Zl6HMDAAAA/Ek2d37zVq1amVtqAgMDJTQ01OW+/fv3y5IlS2Tr1q1St25ds23SpEnSunVree+990xPyJw5cyQuLk5mzJghOXLkkCpVqsiOHTtk3LhxTgEEAAAAgA/XWKxZs0aKFCkiFSpUkL59+8off/xh3xcVFWWGP9lChWrRooVkyZJFNm/ebD+mSZMmJlTYhIWFycGDB+XixYsuv2dsbKzp6XC8AQAAAPDSYKHDoGbPni0rV66UMWPGyNq1a00Px82bN83+M2fOmNDhKFu2bFKgQAGzz3ZMSEiI0zG2+7ZjkoqMjJTg4GD7TesyAAAAAHjoUKhbefLJJ+2fV6tWTapXry7lypUzvRjNmzfPsO8bHh4ugwYNst/XHgvCBQAAAOClPRZJlS1bVgoVKiSHDx8297X24ty5c07HxMfHm5mibHUZ+vHs2bNOx9jup1S7oXUdOsuU4w0AAACAjwSLkydPmhqLokWLmvsNGjSQS5cumdmebFatWiUJCQlSv359+zE6U9SNGzfsx+gMUlqzcdddd7nhWQAAAAC+x63BQteb0Bma9KaOHj1qPj9+/LjZN3jwYNm0aZP8+uuvps7i8ccfl/Lly5via1WpUiVTh9GrVy/ZsmWLbNiwQfr372+GUOmMUKpz586mcFvXt9BpaefPny8TJ050GuoEAAAAwIuDxbZt26RWrVrmpvRkXz8fPny4ZM2a1Sxs99hjj8m9995rgkGdOnVk/fr1ZqiSjU4nW7FiRVNzodPMNmrUyGmNCi2+XrZsmQkt+vUvv/yyeXymmgUAAAB8pHi7adOmkpiYmOL+pUuX3vIxdAaouXPnpnqMFn1rIAEAAACQMbyqxgIAAACAZyJYAAAAALCMYAEAAADAMoIFAAAAAMsIFgAAAAAsI1gAAAAAsIxgAQAAAMAyggUAAAAAywgWAAAAACwjWAAAAACwjGABAAAAwDKCBQAAAADLCBYAAAAALCNYAAAAALCMYAEAAADAMoIFAAAAAMsIFgAAAAAsI1gAAAAAsIxgAQAAAMAyggUAAAAAywgWAAAAACwjWAAAAACwjGABAAAAwDKCBQAAAADLCBYAAAAALCNYAAAAALCMYAEAAADAu4PFunXrpG3btlKsWDEJCAiQhQsX2vfduHFDhgwZItWqVZM8efKYY7p37y6nTp1yeozSpUubr3W8vfPOO07H7Nq1Sxo3biw5c+aUEiVKyNixYzPtOQIAAAD+wK3B4urVq1KjRg2ZPHlysn3Xrl2T7du3y7Bhw8zHBQsWyMGDB+Wxxx5LdmxERIScPn3afhswYIB9X0xMjLRs2VJKlSol0dHR8u6778rIkSNl2rRpGf78AAAAAH+RzZ3fvFWrVubmSnBwsCxfvtxp24cffij16tWT48ePS8mSJe3b8+XLJ6GhoS4fZ86cORIXFyczZsyQHDlySJUqVWTHjh0ybtw46d27dzo/IwAAAMA/eVWNxeXLl81Qp/z58ztt16FPBQsWlFq1apkeifj4ePu+qKgoadKkiQkVNmFhYab34+LFiy6/T2xsrOnpcLwBAAAA8NAeiztx/fp1U3Px1FNPSVBQkH37Cy+8ILVr15YCBQrIxo0bJTw83AyH0h4JdebMGSlTpozTY4WEhNj33XXXXcm+V2RkpIwaNSrDnxMAAADgK7wiWGgh9z//+U9JTEyUKVOmOO0bNGiQ/fPq1aubnol//etfJhwEBgam6ftpOHF8XO2x0KJvAAAAAF4aLGyh4tixY7Jq1Sqn3gpX6tevb4ZC/frrr1KhQgVTe3H27FmnY2z3U6rL0ECS1lACAAAA+KM01ViULVtW/vjjj2TbL126ZPald6g4dOiQrFixwtRR3IoWZmfJkkWKFCli7jdo0MBMa6uPZaNF4Ro6XA2DAgAAAJBJPRbaG3Dz5k2XRc+//fbbbT/OlStX5PDhw/b7R48eNcFA6yWKFi0qnTp1MlPNLl682Hw/rYlQul+HPGlh9ubNm6VZs2ZmZii9P3DgQOnatas9NHTu3NnUS/Ts2dPUaOzZs0cmTpwo48ePT8tTBwAAAGA1WHz77bf2z5cuXWqmhLXRE/+VK1eaBetu17Zt20wosLHVNfTo0cOsNWH7fjVr1nT6utWrV0vTpk3NcKV58+aZYzXUaJG2BgvH+ght47Jly6Rfv35Sp04dKVSokAwfPpypZgEAAAB3BYt27dqZjzrlq578O8qePbsJFe+///5tP56GAy3ITklq+5TOBrVp06Zbfh8t6l6/fv1ttwsAAABABgaLhIQE81F7BrZu3Wqu/gMAAABAmmostBYCAAAAACxPN6v1FHo7d+6cvSfDZsaMGWl9WAAAAAD+Eix0lqWIiAipW7eumb1Jay4AAAAA+K80BYupU6fKrFmzpFu3bunfIgAAAAD+sUBeXFycPPDAA+nfGgAAAAD+Eyyee+45mTt3bvq3BgAAAID/DIW6fv26TJs2TVasWGHWiNA1LByNGzcuvdoHAAAAwFeDxa5du+yrYe/Zs8dpH4XcAAAAgP9JU7BYvXp1+rcEAAAAgH/VWAAAAACA5R6LZs2apTrkadWqVWl5WAAAAAD+FCxs9RU2N27ckB07dph6ix49eqRX2wAAAAD4crAYP368y+0jR46UK1euWG0TAAAAAH+usejatavMmDEjPR8SAAAAgL8Fi6ioKMmZM2d6PiQAAAAAXx0K1aFDB6f7iYmJcvr0adm2bZsMGzYsvdoGAAAAwJeDRXBwsNP9LFmySIUKFSQiIkJatmyZXm0DAAAA4MvBYubMmenfEgAAAAD+FSxsoqOjZf/+/ebzKlWqSK1atdKrXQAAAAB8PVicO3dOnnzySVmzZo3kz5/fbLt06ZJZOG/evHlSuHDh9G4nAAAAAF+bFWrAgAHy559/yt69e+XChQvmpovjxcTEyAsvvJD+rQQAAADgez0WS5YskRUrVkilSpXs2ypXriyTJ0+meBsAAADwQ2nqsUhISJDs2bMn267bdB8AAAAA/5KmYPHQQw/Jiy++KKdOnbJv++2332TgwIHSvHnz9GwfAAAAAF8NFh9++KGppyhdurSUK1fO3MqUKWO2TZo0Kf1bCQAAAMD3aixKlCgh27dvN3UWBw4cMNu03qJFixbp3T4AAAAAvtZjsWrVKlOkrT0TAQEB8vDDD5sZovR23333mbUs1q9ff9uPt27dOmnbtq0UK1bMPN7ChQud9icmJsrw4cOlaNGikitXLhNcDh065HSMzkjVpUsXCQoKMlPf9uzZU65cueJ0zK5du6Rx48aSM2dOE4rGjh17J08bAAAAQHoGiwkTJkivXr3MSXxSwcHB8q9//UvGjRt324939epVqVGjhplNyhUNAB988IFMnTpVNm/eLHny5JGwsDC5fv26/RgNFTrt7fLly2Xx4sUmrPTu3du+X0OQzlRVqlQps6Dfu+++KyNHjpRp06bdyVMHAAAAkF5DoXbu3CljxoxJcb+ewL/33nu3/XitWrUyN1e0t0KDzNChQ+Xxxx8322bPni0hISGmZ0MX6NNVv3Xq261bt0rdunXNMVrj0bp1a9MO7QmZM2eOxMXFyYwZMyRHjhymV2XHjh0mADkGEAAAAACZ1GNx9uxZl9PM2mTLlk3Onz8v6eHo0aNy5swZp7oN7RWpX7++REVFmfv6UYc/2UKF0uOzZMliejhsxzRp0sSEChvt9Th48KBcvHjR5feOjY01PR2ONwAAAADpFCzuvvtus8J2SrSWQesh0oOGCqU9FI70vm2ffixSpEiycFOgQAGnY1w9huP3SCoyMtKEGNtN6zIAAAAApFOw0CFGw4YNc6pxsPnrr79kxIgR8uijj4q3Cw8Pl8uXL9tvJ06ccHeTAAAAAN+psdB6hwULFsi9994r/fv3lwoVKpjtOuWsFmDfvHlT3njjjXRpWGhoqH34lWMviN6vWbOm/Zhz5845fV18fLyZKcr29fpRv8aR7b7tmKQCAwPNDQAAAEAG9FjoEKKNGzdK1apVzVX99u3bm9vrr79utv3444/Jhh2llS64pyf+K1eutG/TWgetnWjQoIG5rx8vXbpkZntynBI3ISHB1GLYjtGZom7cuGE/RmeQ0lB01113pUtbAQAAAH93xwvk6bStP/zwgyl8Pnz4sJm96Z577knTSbquN6GP4ViwrTM2aY1EyZIl5aWXXpI333zTPL4GDR2GpTM9tWvXzr4o3yOPPGKmwNUpaTU8aE+Kzhilx6nOnTvLqFGjzPoWQ4YMMTUiEydOlPHjx99xewEAAACk48rbSoOELopnxbZt26RZs2b2+4MGDTIfe/ToIbNmzZJXX33VrHWh08Jqz0SjRo3M9LK60J2NTierYaJ58+ZmNqiOHTuatS9stPh62bJl0q9fP6lTp44UKlTILLrHVLMAAACABwSL9NC0aVPT45ESXY07IiLC3FKivRtz585N9ftUr179jlYEBwAAAJCBNRYAAAAA4ArBAgAAAIBlBAsAAAAAlhEsAAAAAFhGsAAAAABgGcECAAAAgGUECwAAAACWESwAAAAAWEawAAAAAGAZwQIAAACAZQQLAAAAAJYRLAAAAABYRrAAAAAAYBnBAgAAAIBlBAsAAAAAlhEsAAAAAFhGsAAAAABgGcECAAAAgGXZrD8EAAAA4D6lX/te/MWv77QRT0WPBQAAAADLCBYAAAAALCNYAAAAALCMYAEAAADAMoIFAAAAAMsIFgAAAAAsI1gAAAAAsIxgAQAAAMD3g0Xp0qUlICAg2a1fv35mf9OmTZPt69Onj9NjHD9+XNq0aSO5c+eWIkWKyODBgyU+Pt5NzwgAAADwPR6/8vbWrVvl5s2b9vt79uyRhx9+WP7xj3/Yt/Xq1UsiIiLs9zVA2OjXaqgIDQ2VjRs3yunTp6V79+6SPXt2efvttzPxmQAAAAC+y+ODReHChZ3uv/POO1KuXDl58MEHnYKEBgdXli1bJvv27ZMVK1ZISEiI1KxZU0aPHi1DhgyRkSNHSo4cOTL8OQAAAAC+zuOHQjmKi4uTzz77TJ599lkz5Mlmzpw5UqhQIalataqEh4fLtWvX7PuioqKkWrVqJlTYhIWFSUxMjOzdu9fl94mNjTX7HW8AAAAAvLjHwtHChQvl0qVL8vTTT9u3de7cWUqVKiXFihWTXbt2mZ6IgwcPyoIFC8z+M2fOOIUKZbuv+1yJjIyUUaNGZehzAQAAAHyJVwWL6dOnS6tWrUyIsOndu7f9c+2ZKFq0qDRv3lx++eUXM2QqLbTXY9CgQfb72mNRokQJi60HAAAAfJfXBItjx46ZOglbT0RK6tevbz4ePnzYBAutvdiyZYvTMWfPnjUfU6rLCAwMNDcAAAAAPlZjMXPmTDNVrM7wlJodO3aYj9pzoRo0aCC7d++Wc+fO2Y9Zvny5BAUFSeXKlTO41QAAAIB/8Ioei4SEBBMsevToIdmy/d1kHe40d+5cad26tRQsWNDUWAwcOFCaNGki1atXN8e0bNnSBIhu3brJ2LFjTV3F0KFDzToY9EoAAAAAfhQsdAiULnKns0E50qlidd+ECRPk6tWrpg6iY8eOJjjYZM2aVRYvXix9+/Y1vRd58uQxAcVx3QsAAAAAfhAstNchMTEx2XYNEmvXrr3l1+usUT/88EMGtQ4AAACA19RYAAAAAPBcBAsAAAAAlhEsAAAAAFhGsAAAAABgGcECAAAAgGUECwAAAACWESwAAAAAWEawAAAAAGAZwQIAAACAZQQLAAAAAJYRLAAAAABYRrAAAAAAYBnBAgAAAIBlBAsAAAAAlhEsAAAAAFhGsAAAAABgGcECAAAAgGUECwAAAACWESwAAAAAWEawAAAAAGAZwQIAAACAZQQLAAAAAJYRLAAAAABYRrAAAAAAYBnBAgAAAIBlBAsAAAAAlhEsAAAAAPh2sBg5cqQEBAQ43SpWrGjff/36denXr58ULFhQ8ubNKx07dpSzZ886Pcbx48elTZs2kjt3bilSpIgMHjxY4uPj3fBsAAAAAN+VTTxclSpVZMWKFfb72bL93eSBAwfK999/L19++aUEBwdL//79pUOHDrJhwwaz/+bNmyZUhIaGysaNG+X06dPSvXt3yZ49u7z99ttueT4AAACAL/L4YKFBQoNBUpcvX5bp06fL3Llz5aGHHjLbZs6cKZUqVZJNmzbJ/fffL8uWLZN9+/aZYBISEiI1a9aU0aNHy5AhQ0xvSI4cOdzwjAAAAADf49FDodShQ4ekWLFiUrZsWenSpYsZ2qSio6Plxo0b0qJFC/uxOkyqZMmSEhUVZe7rx2rVqplQYRMWFiYxMTGyd+9eNzwbAAAAwDd5dI9F/fr1ZdasWVKhQgUzjGnUqFHSuHFj2bNnj5w5c8b0OOTPn9/pazRE6D6lHx1DhW2/bV9KYmNjzc1GgwgAAAAALw0WrVq1sn9evXp1EzRKlSolX3zxheTKlSvDvm9kZKQJMQAAAAB8ZCiUI+2duPfee+Xw4cOm7iIuLk4uXbrkdIzOCmWrydCPSWeJst13VbdhEx4ebmo4bLcTJ05kyPMBAAAAfIVXBYsrV67IL7/8IkWLFpU6deqY2Z1Wrlxp33/w4EFTg9GgQQNzXz/u3r1bzp07Zz9m+fLlEhQUJJUrV07x+wQGBppjHG8AAAAAvHQo1CuvvCJt27Y1w59OnTolI0aMkKxZs8pTTz1lppft2bOnDBo0SAoUKGBO/gcMGGDChM4IpVq2bGkCRLdu3WTs2LGmrmLo0KFm7QsNDwAAAAD8IFicPHnShIg//vhDChcuLI0aNTJTyernavz48ZIlSxazMJ4WW+uMT//+97/tX68hZPHixdK3b18TOPLkySM9evSQiIgINz4rAAAAwPd4dLCYN29eqvtz5swpkydPNreUaG/HDz/8kAGtAwAAAOCVNRYAAAAAPBPBAgAAAIBlBAsAAAAAlhEsAAAAAFhGsAAAAABgGcECAAAAgGUECwAAAACWESwAAAAAWEawAAAAAGAZwQIAAACAZQQLAAAAAJYRLAAAAABYRrAAAAAAYBnBAgAAAIBlBAsAAAAAlhEsAAAAAFhGsAAAAABgGcECAAAAgGUECwAAAACWESwAAAAAWEawAAAAAGAZwQIAAACAZQQLAAAAAJYRLAAAAABYRrAAAAAAYBnBAgAAAIBlBAsAAAAAvh0sIiMj5b777pN8+fJJkSJFpF27dnLw4EGnY5o2bSoBAQFOtz59+jgdc/z4cWnTpo3kzp3bPM7gwYMlPj4+k58NAAAA4LuyiQdbu3at9OvXz4QLDQKvv/66tGzZUvbt2yd58uSxH9erVy+JiIiw39cAYXPz5k0TKkJDQ2Xjxo1y+vRp6d69u2TPnl3efvvtTH9OAAAAgC/y6GCxZMkSp/uzZs0yPQ7R0dHSpEkTpyChwcGVZcuWmSCyYsUKCQkJkZo1a8ro0aNlyJAhMnLkSMmRI0eGPw8AAADA13n0UKikLl++bD4WKFDAafucOXOkUKFCUrVqVQkPD5dr167Z90VFRUm1atVMqLAJCwuTmJgY2bt3bya2HgAAAPBdHt1j4SghIUFeeukladiwoQkQNp07d5ZSpUpJsWLFZNeuXaYnQuswFixYYPafOXPGKVQo233d50psbKy52WgIAQAAAOADwUJrLfbs2SM//vij0/bevXvbP9eeiaJFi0rz5s3ll19+kXLlyqW5aHzUqFGW2wwAAAD4C68YCtW/f39ZvHixrF69WooXL57qsfXr1zcfDx8+bD5q7cXZs2edjrHdT6kuQ4dT6bAr2+3EiRPp9EwAAAAA3+TRwSIxMdGEim+++UZWrVolZcqUueXX7Nixw3zUngvVoEED2b17t5w7d85+zPLlyyUoKEgqV67s8jECAwPNfscbAAAAAC8dCqXDn+bOnSuLFi0ya1nYaiKCg4MlV65cZriT7m/durUULFjQ1FgMHDjQzBhVvXp1c6xOT6sBolu3bjJ27FjzGEOHDjWPrQECAAAAgI/3WEyZMsUMRdJF8LQHwnabP3++2a9Txeo0shoeKlasKC+//LJ07NhRvvvuO/tjZM2a1Qyj0o/ae9G1a1ezjoXjuhcAAAAAfLjHQodCpaZEiRJmEb1b0Vmjfvjhh3RsGQAAAACv6bEAAAAA4B0IFgAAAAAsI1gAAAAAsIxgAQAAAMAyggUAAAAAywgWAAAAACwjWAAAAACwjGABAAAAwDKCBQAAAADLCBYAAAAALCNYAAAAALCMYAEAAADAMoIFAAAAAMsIFgAAAAAsI1gAAAAAsIxgAQAAAMAyggUAAAAAywgWAAAAACwjWAAAAACwjGABAAAAwDKCBQAAAADLCBYAAAAALCNYAAAAALCMYAEAAADAMoIFAAAAAMsIFgAAAAAsI1gAAAAAsMyvgsXkyZOldOnSkjNnTqlfv75s2bLF3U0CAAAAfILfBIv58+fLoEGDZMSIEbJ9+3apUaOGhIWFyblz59zdNAAAAMDr+U2wGDdunPTq1UueeeYZqVy5skydOlVy584tM2bMcHfTAAAAAK/nF8EiLi5OoqOjpUWLFvZtWbJkMfejoqLc2jYAAADAF2QTP/D777/LzZs3JSQkxGm73j9w4ECy42NjY83N5vLly+ZjTEyMZLaE2GviL9zx83UHXlPfxOvqm/zldeU19U28rr4pJpNfV9v3S0xMvOWxfhEs7lRkZKSMGjUq2fYSJUq4pT3+IniCu1uA9MZr6pt4XX0Pr6lv4nX1TcFuel3//PNPCQ4OTvUYvwgWhQoVkqxZs8rZs2edtuv90NDQZMeHh4ebQm+bhIQEuXDhghQsWFACAgLEl2kq1QB14sQJCQoKcndzkE54XX0Pr6lv4nX1TbyuvsefXtPExEQTKooVK3bLY/0iWOTIkUPq1KkjK1eulHbt2tnDgt7v379/suMDAwPNzVH+/Pkzrb2eQN8kvv5G8Ue8rr6H19Q38br6Jl5X3+Mvr2nwLXoq/CpYKO2B6NGjh9StW1fq1asnEyZMkKtXr5pZogAAAABY4zfB4oknnpDz58/L8OHD5cyZM1KzZk1ZsmRJsoJuAAAAAHfOb4KF0mFProY+4W86BEwXEUw6FAzejdfV9/Ca+iZeV9/E6+p7eE1dC0i8nbmjAAAAAMDfF8gDAAAAkLEIFgAAAAAsI1gAAAAAsIxgAQAAAMAyggUAAAAAywgWsIuLi5ODBw9KfHy8u5uCdKCv44oVK+Sjjz6SP//802w7deqUXLlyxd1NQzrg/eo71q9fL127dpUGDRrIb7/9ZrZ9+umn8uOPP7q7aUgn169fd3cTgExBsIBcu3ZNevbsKblz55YqVarI8ePHzfYBAwbIO++84+7mIQ2OHTsm1apVk8cff1z69etnFodUY8aMkVdeecXdzYMFvF99y9dffy1hYWGSK1cu+emnnyQ2NtZsv3z5srz99tvubh4sSEhIkNGjR8vdd98tefPmlSNHjpjtw4YNk+nTp7u7eUgjDf0NGzaUYsWKmf+1asKECbJo0SJ3N80jECwg4eHhsnPnTlmzZo3kzJnTvr1FixYyf/58t7YNafPiiy9K3bp15eLFi+aExaZ9+/aycuVKt7YN1vB+9S1vvvmmTJ06Vf7zn/9I9uzZ7dv1xGX79u1ubRusv7azZs2SsWPHSo4cOezbq1atKh9//LFb24a0mTJligwaNEhat24tly5dkps3b5rt+fPnN+ECBAuIyMKFC+XDDz+URo0aSUBAgH27Xg395Zdf3No2pH1oxdChQ53+manSpUvbh1rAO/F+9S06nK1JkybJtgcHB5sTF3iv2bNny7Rp06RLly6SNWtW+/YaNWrIgQMH3No2pM2kSZPMRYA33njD6TXVC3m7d+92a9s8BcECZphMkSJFkm2/evWq04kLvKsL3nYlxdHJkyclX758bmkT0gfvV98SGhoqhw8fTrZd6yvKli3rljYhfehFnPLly7v8+3zjxg23tAnWHD16VGrVqpVse2BgoPkbDIIF/j9pf//99/b7tpMT7arVYkJ4n5YtWzp1y+prqkXbI0aMMF248F68X31Lr169zNDFzZs3m9dSJ1iYM2eOqYXq27evu5sHCypXrmx6j5P66quvXJ6cwvOVKVNGduzYkWz7kiVLpFKlSm5pk6fJ5u4GwP20QLBVq1ayb98+M8PMxIkTzecbN26UtWvXurt5SIP333/fFITqPzadjaRz585y6NAhKVSokHz++efubh4s4P3qW1577TVzBbt58+amMF+HRenVTw0WWpAP7zV8+HDp0aOH6bnQ13jBggVm6JsOkVq8eLG7m4c00PoKnRBF/68mJibKli1bzP/UyMhI6mb+X0Ci/mTg93Rsts4oo0WhemW7du3aMmTIEDOzELyTnnRqMa/ja6pjfR2LueGdeL/65vTBOiRKX0+9IKCzCMH7aY9FRESE03tVA4f2KsM7aY/iyJEj7TVtOjvUqFGjzGx9IFgAAAAAt7xYN3fuXDMaICQkxPQwalh0VfPmzwgWsM+Dn5KSJUtmWluQPj755BMz7KlNmzbm/quvvmpmJ9ErodptW6pUKXc3EWnE+9W3NGvWLNWi+1WrVmVqewCkTNcP2r9/P/9DU0GNBcwUpKn9Y3M1uxA8fxy+zretoqKizPSkWsyt43oHDhxoxvrCO/F+9S01a9Z0uq+zBWlx6J49e8z4fHivLFmy8F71MfXq1TMLWRIsUkawgHmTJP3HptvGjRsnb731ltvahbQ7ceKEfZpDXfegU6dO0rt3b7PoVtOmTd3dPFjA+9W3jB8/3uV2HcOtwyzgvb755huX71XtUdYx+fA+zz//vLz88stm6vY6depInjx5nPZXr15d/B1DoZAindLy3XffNSv8wrvomM+lS5eaKQ31pjNZdOvWzRSb6eJMnLD4Ht6vvkULufXq6IULF9zdFKQzHaevE2ssWrTI3U1BGnqhktJeKT2V1o836YWixwIpq1ChgmzdutXdzUAaPPzww/Lcc8+ZUPHzzz/b167Yu3evGUoD38P71bfoEMacOXO6uxnIAPfff7/pQYZ3LpCH1BEsIDExMU73NXmfPn3adMXfc889bmsX0m7y5MkydOhQMyTq66+/loIFC5rt0dHR8tRTT7m7ebCA96tv6dChg8vXc9u2bTJs2DC3tQsZ46+//pIPPvhA7r77bnc3BWlAbcWtMRQKLgvM9NeiRIkSMm/ePFbzBTwI71ff8swzzyR7fQsXLiwPPfQQax14ubvuusvpvarv0z///NPMLPTZZ5/JY4895tb24fZ8++23ZlHS7Nmzm89T8xivKcECkmy1Xts/Ni3+zZaNTi1vsWvXrts+lgIz78X71XfoeOwNGzaYhQ31JBS+RYu0Xb1X69evz+vtRfR1O3PmjKlddFVjYUONxf/wX8jP6SwV+sdPu9zLlCnj7ubA4rSVtiIyVygw8368X31L1qxZTa+EzovPiabvLaZ27NgxefbZZ6V48eLubg4sSEhIcPk5XKPHAhIcHGzmTedExbvpP7HbxThR78X71bfUrVtXxowZI82bN3d3U5DO8uXLJ7t372bCDC9XoEABMwmKLjqrQXHixInmtYVrBAuYRZj0arcunAbAs/F+9S1LliyR8PBwGT16tMt58YOCgtzWNljz+OOPm+J8Fjr0bnnz5jVDjcuWLWt6GXVYlA5pg2sMhYKZSSYiIsKM9XX1j+2FF15wW9tgzb59++T48eMSFxfntJ0CM+/F+9W32KaC1vdk0kJfhi16Ny34fe2110yvhav3Kn+HvYNOiNGuXTvzGur7Uv/G5sqVy+WxM2bMEH9HjwVSHVKh/9iOHDmSqe2BdfqatW/f3vxDc6y7sJ24cLLivXi/+hatmdEZvfRKqCMdy60XBbja7b0o9PUNZ8+elfHjx5sFZhcsWCBhYWESGBh4W6ut+yOCBeCD2rZta05UPv74Y3MiumXLFvnjjz/k5Zdflvfee08aN27s7iYC+P8Cbl23QmeccaTvV93GySfgOfT/qa4xY1sbCsmlHKfhN3RYxbVr11wu5KP74J2r9uprp8VmetVMb40aNZLIyEiGyng53q++xTbkKakrV66w8raXmz17tsTGxibbrkNTdR+8c+VtW6g4efIks0S5QI8FuGLmg3Tqyu3bt5urK+XKlTM9F82aNTNduTpnvqsTU3gH3q++YdCgQeajzjDTq1cvs2iajb6GmzdvNq+11tLAO/Fe9W06sYLO0KdF3fgbxdtI8YrZzp07zTRr8D5Vq1Y1r58GC12MaezYsZIjRw6ZNm0afwS9HO9X3/DTTz/ZX0+thdL3p41+XqNGDXnllVfc2EJk1HtVr3TrtNHwblyXd41g4edXtfWPnt7uvfdepz+AeiVFu+L79Onj1jbi9ul0eBoodNjT0KFD7b0SOjzm0UcfNXUV2oU7f/58dzcVacD71besXr3afHzmmWdMrwXTyvqOWrVq2d+ruj5JtmzZnN6rOpzmkUcecWsbgYzCUCg/n41EX35d8GXChAlOV1D0ipku6qPTrMH7ut21V2Lr1q1OBWYXLlywn5zC+/B+BbzDqFGj7B91wgxdByHpe7Vjx45OvVTwPlqz2LdvX8mfP7+7m+JRCBaQtWvXSsOGDZ2uqsD7aIj44YcfzNAn7bXQKfJYxMf38H4FvOdiwBNPPEERvg/THigdyliqVClz4Q7MCgURefDBB+0nKW3atDFXveF99AqYvpZaV6G9EnXr1jU9F65u8F68XwHvoGuQ2ELF888/L7///ru7mwSLXnrpJZk+fbo9VOjf49q1a5u1aNasWePu5nkEeizgJF++fKYIlJNP77RkyRI5fPiwmVJWayv09XTlxRdfzPS2If3xfgW8AzMI+YbixYvLwoULzYU7/aiBUQPFp59+KqtWrWIWN4q3Ad9iKwiMjo424SGlYAEAyDxcw/UN2usUGhpqPtehx//85z/NZBpa+6aTMIChUH7rgw8+kOvXr5vPjx8/bv+jp+MEs2fP7ubWwaqZM2cSKvwA71cAyDwhISGyb98+MwxKRwg8/PDDZrvOwqgTqIChUH5Lx2ifOnXKzCCU0iI+ADzPkSNHGE4BeIGrV69Knjx53N0MpKORI0eaWfmKFi1qwsTPP/8sgYGBMmPGDPnPf/4jUVFR4u8YCuWnihUrJl9//bW0bt3a9Fbogj22HoykSpYsmentA+Ba+fLlTcFgz549pVOnTsw4A3jw1W0dKqPDZBo1auTu5iCdgoWuF3XixAn5xz/+YUKF0gu0r732mrub5xHosfBTugLzgAEDJD4+/parhmqXHwDPoAWgOtTt888/l7i4ODOdpYaMevXqubtpABxoce+sWbPMWHxdu0IDRvfu3c2FPXin2bNnm7+5tkBho3+L582bZ15ff0ew8GN//vmnHDt2TKpXry4rVqxwWkzNUY0aNTK9bQBSpxcFvv32W3PiomN9bQWE3bp1Y/0SwIOcP3/ezBqk79X9+/dLWFiYea8+9thjrEfjZVIaOv7HH3+YbTe5EEuwwP8W8XnyySeTJXAAni82Nlb+/e9/S3h4uLlqpqv56vCLMWPGmHHAADzHpEmTZPDgwea9WqhQIenTp48ZQpM7d253Nw23IaXFZ3Xa72bNmsmFCxfE3xEsAMALbdu2zRQMave7FojqYlw6JErrpUaNGiUxMTGyZcsWdzcT8Ht6IqoX8LTHQkcJtG/f3v5e1QsAOjRq2bJl7m4mUlGrVi0zNFwDRJUqVZx6mrSX4ujRo2a69y+++EL8HX1wfkqXntc3ye0ggQOeY9y4cabG4uDBg2byBR3zqx/1SprSldf1BEbHdANwnwULFpj36tKlS6Vy5cpmMbWuXbtK/vz57cc88MADUqlSJbe2E7fWrl07e42bDmXLmzevfZ/2Euvf244dO7qxhZ6DYOGndLo0AN5nypQpZnz2008/neJQJx3rO3369ExvG4C/PfPMM2aYsa7GfN9997k8Rnsr3njjjUxvG+7MiBEjzEcNEFq8zWx8KWMoFAAAQDrTdQ6onfBNWiNz7tw5SUhIcNpekun5CRZwpmtZ6BvGUVBQkNvaA0Bk165dt32szvIGwD20tul28b/V+xw6dMj0GG/cuNFpO9Pz/41gAbM66JAhQ0zRkU6ZlhRvFMC9tH5C/2ml9Ofato9/bIBnvFdTw3vVezVs2NAUbutMXjoUNelrXYPp+amxgMirr74qq1evNmO3dQ78yZMny2+//SYfffSRvPPOO+5uHuD3dMYRAJ5P/5fCd2nxdnR0tFSsWNHdTfFYBAvId999Z2aWadq0qSk2a9y4sZQvX15KlSolc+bMkS5duri7iYBf0/eizbp168xMMkkX1tIF87R73vFYAJnrwQcfdHcTkIF0dq/ff//d3c3waP+bnxB+TaeTLVu2rH3Mp2162UaNGpmTGACeI6VFmC5fvmz2AfAc69evN1PM6sUAHQmgdBXuH3/80d1NQxrouiM6ymPNmjVm6LjW1DjeQLCAiAkVtqEW2r1nW+BFezIc59sG4H628dlJ6T85XSgPgGf4+uuvzZoHuXLlku3bt0tsbKz9IsDbb7/t7uYhDVq0aCGbNm2S5s2bm2m9dU0wvem5kn4EQ6Hw/3Nt62qS2oWrBUlt27aVDz/8UG7cuGEW4wLgfh06dDAfNVToGhaBgYH2fVoEqjNH6VVRAJ7hzTfflKlTp0r37t1l3rx5TgXAug/ehxqaWyNYQAYOHOiUxg8cOGCKk7TOgqkrAc8QHBxs77HIly+fuQrquPLr/fffL7169XJjCwE4OnjwoDRp0sTle/nSpUtuaROsoYbm1ggWMFauXGlurhZ8mTFjhtvaBeB/Zs6caV/59ZVXXmHYE+DhQkND5fDhw+Y960jrK2x1jfDexQ+PHz+ebN2v6lyMJVhAZNSoURIRESF169Z1OS8zAM+hhYOO61kcO3ZMvvnmGzNbScuWLd3aNgB/0x7EF1980Vyc0/+rp06dkqioKHNhYNiwYe5uHtLg/PnzZvj4f//7X5f7b7I2CcECYsaAzpo1y6xhAcCzPf7446beok+fPmY4Rb169cxQKJ0CUWui+vbt6+4mAhAxNYs6AkALffUKtw6L0tooDRYDBgxwd/OQBi+99JL5u7t582YzRb9e1Dl79qypmXn//ffd3TyPwMrbkIIFC8qWLVukXLly7m4KgFsoVKiQrF27VqpUqSIff/yxTJo0SX766SczA83w4cNl//797m4i4Pf0yvWGDRvM0JjcuXObIVFXrlwxPYt58+Z1d/OQRjqqY9GiReaCjk7Pv23bNrn33nvl22+/lbFjxzKNMNPNQj333HMyd+5cdzcDwG3QK59avK2WLVtmei+yZMliird1WBQA98uaNasZmnjx4kXTo6iBQk9GCRXe7erVq2aaWaXTy+rQKFWtWjUzpTAYCuW3Bg0aZP9cu2qnTZsmK1asMFdXsmfP7nQsU84CnkNna1u4cKG0b99eli5dap/VTSde0CtoADxD1apV5ciRI1KmTBl3NwXppEKFCma2Ly3Ir1Gjhnz00Ufmcx1Srr0ZYCiU37rdFXq14GzVqlUZ3h4At+err76Szp07m6EWDz30kCxfvtxsj4yMlHXr1qVYVAggcy1ZskTCw8Nl9OjRUqdOnWQzuXEhwPt89tlnEh8fb9YS0mn5H3nkEbM4qfZKffLJJ/LEE0+IvyNYAICXOXPmjJw+fdpcMdNhUErrpPREpWLFiu5uHgAda/7/703lONuinnbpfWYQ8m76Ov71119m7a+SJUua+jcQLADAa508edJ8LF68uLubAiAJnWQhNSy25p2mT58u48ePl0OHDpn799xzj5ktSutVQY0FAHgVrYmyTW2os8woLeZ++eWX5Y033nC6SgrAfQgOvkdn3tO6U50uuEGDBmabrk2itW66YF5ERIT4O3osAMCL6JhtvWKmC1s2bNjQbNMpDkeOHGkW5Hrrrbfc3UQADlil2XcULlxYPvjgA3nqqaectn/++ecmbPz+++/i7wgWAOBFihUrZmYgeeyxx5y269zqzz//vPz2229uaxuAv7FKs+/Jnz+/bN261Qx/cvTzzz+b6YQvXbok/o4+cwDwIhcuXHBZoK3bdB8Az1ulOVeuXGaWKJ05SE9KdUE1eJ9u3brJlClTkm3XKfu7dOniljZ5GnosAMCL1K9f39y0O96RdsPrlbRNmza5rW0A/sYqzb5H/87Onj1bSpQoYRYlVRocdahb9+7dndYB89c1wCjeBgAvoickbdq0MQtaOhYP6j821rAAPHuVZg0WrNLsvfbs2SO1a9c2n//yyy/mo04zqzfd52p6YX9DsAAAL5tpRld+1e74/fv3m20dOnQw9RVafwHAM7BKs+9ZvXq1u5vg8RgKBQBe5vr167Jr1y45d+6cmX7WUdKibgDuwSrN8EcECwDwIloAqmN59QQl6Z9vVvMFPBOrNMNfMCsUAHhZ8eA//vEPOXXqlOmtcLwRKgDPomvOVK1aVXLmzGnqLPSiwMKFC93dLCDDUGMBAF7k7NmzMmjQIAkJCXF3UwCkglWa4Y8YCgUAXuTZZ581K2737NnT3U0BkApWaYY/IlgAgBe5du2aGQqlJy06baXjvOnqhRdecFvbAPyNVZrhjwgWAOBlY7b79OljxmwXLFjQab50/fzIkSNubR+A/9FeCQ3+SRdKe+WVV0wh9+TJk93WNiCjECwAwIuEhoaaXonXXntNsmRh/g3Ak2j9k41ONTtr1iwzC5SrVZonTZrkxpYCGYNgAQBepECBAmZ4Rbly5dzdFABJNGvW7LaO097FVatWZXh7gMxGsAAAL6Izymh9xeuvv+7upgAA4ITpZgHAi+haFWPHjpWlS5dK9erVkxVvJx3PDQBAZqHHAgB8ZKgFwysAAO5EsAAAAABgGVOKAAAAALCMYAEAAADAMoIFAAAAAMsIFgAAAAAsI1gAADyWrlycP39+y4+jM2YtXLgwXdoEAHCNYAEAyFBPP/20tGvXzt3NAABkMIIFAAAAAMsIFgAAt9GVwqtVqyZ58uSREiVKyPPPPy9XrlxJdpwOY7rnnnskZ86cEhYWJidOnHDav2jRIqldu7bZX7ZsWRk1apTEx8dn4jMBABAsAABukyVLFvnggw9k79698sknn5iVw1999VWnY65duyZvvfWWzJ49WzZs2CCXLl2SJ5980r5//fr10r17d3nxxRdl37598tFHH5naDP0aAEDmYeVtAECG11hoGLid4umvvvpK+vTpI7///ru5rwHhmWeekU2bNkn9+vXNtgMHDkilSpVk8+bNUq9ePWnRooU0b95cwsPD7Y/z2WefmYBy6tQpe/H2N998Q60HAGSgbBn54AAApGbFihUSGRlpwkJMTIwZvnT9+nXTS5E7d25zTLZs2eS+++6zf03FihXNTFH79+83wWLnzp2mJ8Oxh+LmzZvJHgcAkLEIFgAAt/j111/l0Ucflb59+5pQUKBAAfnxxx+lZ8+eEhcXd9uBQGsytKaiQ4cOyfZpzQUAIHMQLAAAbhEdHS0JCQny/vvvm1oL9cUXXyQ7Tnsxtm3bZnon1MGDB83QKh0OpbRoW7eVL18+k58BAMARwQIAkOEuX74sO3bscNpWqFAhuXHjhkyaNEnatm1rhjNNnTo12ddmz55dBgwYYIq8dVhU//795f7777cHjeHDh5uej5IlS0qnTp1MSNHhUXv27JE333wz054jAPg7ZoUCAGS4NWvWSK1atZxun376qZludsyYMVK1alWZM2eOqbdISodEDRkyRDp37iwNGzaUvHnzyvz58+37dfrZxYsXy7Jly0wthoaO8ePHS6lSpTL5WQKAf2NWKAAAAACW0WMBAAAAwDKCBQAAAADLCBYAAAAALCNYAAAAALCMYAEAAADAMoIFAAAAAMsIFgAAAAAsI1gAAAAAsIxgAQAAAMAyggUAAAAAywgWAAAAACwjWAAAAAAQq/4P2SdO8yZ3xBYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "train_df[\"label\"].value_counts().plot(kind='bar')\n",
    "plt.title(\"Label Distribution in Train Set\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "af95fd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features: ['id', 'label', 'statement', 'subject', 'speaker', 'job_title', 'state', 'party', 'context']\n",
      "Numerical features: ['barely_true', 'false', 'half_true', 'mostly_true', 'pants_fire']\n"
     ]
    }
   ],
   "source": [
    "# Separate categorical and numerical features\n",
    "categorical_features = train_df.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_features = train_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "print(\"Numerical features:\", numerical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2360d4",
   "metadata": {},
   "source": [
    "##### Dropping `id` column  \n",
    "- The `id` column is just a unique identifier and does not provide any predictive power. We will drop it from our dataset before training the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fb1df805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'id' column from train, valid, and test datasets\n",
    "train_df = train_df.drop(columns=[\"id\"])\n",
    "valid_df = valid_df.drop(columns=[\"id\"])\n",
    "test_df = test_df.drop(columns=[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "15a89455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing numerical values\n",
    "train_df = train_df.dropna(subset=['barely_true', 'false', 'half_true', 'mostly_true', 'pants_fire'])\n",
    "valid_df = valid_df.dropna(subset=['barely_true', 'false', 'half_true', 'mostly_true', 'pants_fire'])\n",
    "test_df  = test_df.dropna(subset=['barely_true', 'false', 'half_true', 'mostly_true', 'pants_fire'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d070284b",
   "metadata": {},
   "source": [
    "##### Encoding the `label` Column\n",
    "- We map the textual labels to numbers because machine learning models require numerical targets.  \n",
    "- Each class is assigned a unique number. Although the numbers are ordered, they do **not** imply importance or magnitude; they are just identifiers for the classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "11dd1cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "3    2114\n",
       "1    1993\n",
       "4    1962\n",
       "5    1676\n",
       "2    1654\n",
       "0     839\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the mapping\n",
    "label_mapping = {\n",
    "    \"pants-fire\": 0,\n",
    "    \"false\": 1,\n",
    "    \"barely-true\": 2,\n",
    "    \"half-true\": 3,\n",
    "    \"mostly-true\": 4,\n",
    "    \"true\": 5\n",
    "}\n",
    "\n",
    "# Apply the mapping to train, valid, and test datasets\n",
    "train_df[\"label\"] = train_df[\"label\"].map(label_mapping)\n",
    "valid_df[\"label\"] = valid_df[\"label\"].map(label_mapping)\n",
    "test_df[\"label\"]  = test_df[\"label\"].map(label_mapping)\n",
    "\n",
    "# Verify\n",
    "train_df[\"label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5bf513",
   "metadata": {},
   "source": [
    "#### Handling \"Context\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "42c899dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique contexts in train: ['a mailer' 'a floor speech.' 'Denver' ...\n",
      " 'a recorded telephone message to Cranston residents'\n",
      " 'interview on \"The Colbert Report\"'\n",
      " \"a televised debate on Miami's WPLG-10 against Kendrick Meek.\"]\n",
      "Number of unique contexts: 4345\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique contexts in train:\", train_df['context'].unique())\n",
    "print(\"Number of unique contexts:\", train_df['context'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f07c5b",
   "metadata": {},
   "source": [
    "### Dropping 'context' Feature\n",
    "- We are dropping the 'context' feature because it has **extremely high cardinality** (4,345 unique values).  \n",
    "- One-Hot Encoding would create thousands of sparse columns, which is inefficient and may not improve model performance.  \n",
    "- Most of the textual information is already captured in the 'statement' column, so dropping 'context' is a practical choice for this project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d84d56b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'context' column from train, valid, and test datasets\n",
    "train_df = train_df.drop(columns=['context'])\n",
    "valid_df = valid_df.drop(columns=['context'])\n",
    "test_df  = test_df.drop(columns=['context'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "67a4790e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Train_Missing  Validation_Missing  Test_Missing    Dtype\n",
      "label                    0                   0             0    int64\n",
      "statement                0                   0             0   object\n",
      "subject                  0                   0             0   object\n",
      "speaker                  0                   0             0   object\n",
      "job_title             2896                 345           325   object\n",
      "state                 2208                 279           262   object\n",
      "party                    0                   0             0   object\n",
      "barely_true              0                   0             0  float64\n",
      "false                    0                   0             0  float64\n",
      "half_true                0                   0             0  float64\n",
      "mostly_true              0                   0             0  float64\n",
      "pants_fire               0                   0             0  float64\n"
     ]
    }
   ],
   "source": [
    "missing_summary = pd.concat([\n",
    "    train_df.isnull().sum().rename('Train_Missing'),\n",
    "    valid_df.isnull().sum().rename('Validation_Missing'),\n",
    "    test_df.isnull().sum().rename('Test_Missing'),\n",
    "    train_df.dtypes.rename('Dtype')\n",
    "], axis=1)\n",
    "\n",
    "print(missing_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d415762a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique subject in train: 3827\n",
      "Unique subject in valid: 734\n",
      "Unique subject in test:  732\n",
      "----------------------------------------\n",
      "Unique speaker in train: 2910\n",
      "Unique speaker in valid: 662\n",
      "Unique speaker in test:  636\n",
      "----------------------------------------\n",
      "Unique party in train: 23\n",
      "Unique party in valid: 16\n",
      "Unique party in test:  16\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Check unique values in categorical features\n",
    "for col in [\"subject\", \"speaker\", \"party\"]:\n",
    "    print(f\"Unique {col} in train: {train_df[col].nunique()}\")\n",
    "    print(f\"Unique {col} in valid: {valid_df[col].nunique()}\")\n",
    "    print(f\"Unique {col} in test:  {test_df[col].nunique()}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5aa2d2",
   "metadata": {},
   "source": [
    "### Handling `party` Feature  \n",
    "\n",
    "We are keeping the **party** feature because political affiliation is often strongly correlated with the type of statements made and their truthfulness.  \n",
    "\n",
    "- **Why One-Hot Encoding?**  \n",
    "  - `party` has only 23 unique categories, which is a manageable number.  \n",
    "  - One-hot encoding avoids introducing any false ordering (which would happen with label encoding).  \n",
    "  - It keeps the feature interpretable and works well with most machine learning algorithms.  \n",
    "\n",
    "- **Why not other methods?**  \n",
    "  - *Label Encoding*: Imposes an artificial ranking among parties (e.g., republican > democrat), which doesnâ€™t make sense.  \n",
    "  - *Frequency Encoding*: Would compress categories into a single number but lose interpretability.  \n",
    "  - *Dropping the feature*: Would discard potentially useful information.  \n",
    "\n",
    "ðŸ‘‰ Therefore, we apply **One-Hot Encoding** to `party`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "95c19dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (10238, 34)\n",
      "Validation shape: (1284, 34)\n",
      "Test shape: (1267, 34)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode 'party' for train, valid, and test\n",
    "train_df = pd.get_dummies(train_df, columns=[\"party\"], prefix=\"party\")\n",
    "valid_df = pd.get_dummies(valid_df, columns=[\"party\"], prefix=\"party\")\n",
    "test_df  = pd.get_dummies(test_df,  columns=[\"party\"], prefix=\"party\")\n",
    "\n",
    "# Align columns so all datasets have the same structure\n",
    "train_df, valid_df = train_df.align(valid_df, join='left', axis=1, fill_value=0)\n",
    "train_df, test_df  = train_df.align(test_df,  join='left', axis=1, fill_value=0)\n",
    "\n",
    "# Convert one-hot columns to integers\n",
    "party_cols = [col for col in train_df.columns if col.startswith(\"party_\")]\n",
    "train_df[party_cols] = train_df[party_cols].astype(int)\n",
    "valid_df[party_cols] = valid_df[party_cols].astype(int)\n",
    "test_df[party_cols]  = test_df[party_cols].astype(int)\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Validation shape:\", valid_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580f0f76",
   "metadata": {},
   "source": [
    "### Handling `subject` Feature  \n",
    "\n",
    "We are keeping the **subject** feature because it provides information about the topic of the statement, which can be useful for predicting its veracity.  \n",
    "\n",
    "- **Why TF-IDF vectorization?**  \n",
    "  - `subject` has very high cardinality (~3800 unique values), making one-hot encoding impractical.  \n",
    "  - TF-IDF converts text into numerical features while preserving semantic information.  \n",
    "  - Allows the model to understand similarities between topics (e.g., \"healthcare\" and \"medicare\").  \n",
    "\n",
    "- **Why not other methods?**  \n",
    "  - *One-hot Encoding*: Too many columns â†’ inefficient and sparse.  \n",
    "  - *Label Encoding*: Imposes artificial ordering â†’ meaningless for categories.  \n",
    "  - *Dropping the feature*: Would lose potentially useful predictive information.  \n",
    "\n",
    "ðŸ‘‰ Therefore, we apply **TF-IDF vectorization** to `subject`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b47c15a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train subject features: (10238, 178)\n"
     ]
    }
   ],
   "source": [
    "# Join subject text (if necessary) - here it's already a string\n",
    "train_subjects = train_df['subject'].fillna(\"\").astype(str)\n",
    "valid_subjects = valid_df['subject'].fillna(\"\").astype(str)\n",
    "test_subjects  = test_df['subject'].fillna(\"\").astype(str)\n",
    "\n",
    "# Initialize TF-IDF vectorizer for subject\n",
    "tfidf_subject = TfidfVectorizer(max_features=500)  # limit to 500 for efficiency\n",
    "\n",
    "# Fit on train and transform train, valid, test\n",
    "X_train_subject = tfidf_subject.fit_transform(train_subjects)\n",
    "X_valid_subject = tfidf_subject.transform(valid_subjects)\n",
    "X_test_subject  = tfidf_subject.transform(test_subjects)\n",
    "\n",
    "print(\"Shape of train subject features:\", X_train_subject.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a63f1b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns=['subject'])\n",
    "valid_df = valid_df.drop(columns=['subject'])\n",
    "test_df  = test_df.drop(columns=['subject'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d1a801",
   "metadata": {},
   "source": [
    "### Handling `speaker` Feature\n",
    "\n",
    "We are keeping the **speaker** feature because some speakers may consistently make statements with certain veracity patterns, which can help the model.\n",
    "\n",
    "- **Why Frequency Encoding?**\n",
    "  - `speaker` has very high cardinality (~2910 unique values), so one-hot encoding would create too many sparse columns.\n",
    "  - Frequency encoding replaces each speaker with the number of statements they have in the training set.\n",
    "  - This converts the feature into a meaningful numerical value without exploding dimensionality.\n",
    "\n",
    "- **Why not other methods?**\n",
    "  - *One-hot Encoding*: Creates thousands of columns â†’ inefficient.\n",
    "  - *Label Encoding*: Artificial ordering â†’ meaningless.\n",
    "  - *TF-IDF*: Not very informative for proper names.\n",
    "  - *Dropping the feature*: Loses potentially useful predictive information.\n",
    "\n",
    "ðŸ‘‰ Therefore, we apply **frequency encoding** to `speaker`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ec4296b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate frequency of each speaker in train set\n",
    "speaker_freq = train_df['speaker'].value_counts().to_dict()\n",
    "\n",
    "# Overwrite 'speaker' column with frequency encoding\n",
    "train_df['speaker'] = train_df['speaker'].map(speaker_freq).fillna(0)\n",
    "valid_df['speaker'] = valid_df['speaker'].map(speaker_freq).fillna(0)\n",
    "test_df['speaker']  = test_df['speaker'].map(speaker_freq).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1edd8d3",
   "metadata": {},
   "source": [
    "### Handling `state` Feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0dc56f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique states in train: ['Texas' 'Virginia' 'Illinois' 'Unknown' 'Florida' 'Wisconsin'\n",
      " 'New Jersey' 'Vermont' 'Massachusetts' 'Maryland' 'Washington, D.C. '\n",
      " 'Oregon' 'New York' 'Washington, D.C.' 'California' 'Missouri'\n",
      " 'Rhode Island' 'West Virginia' 'Arkansas' 'New Hampshire' 'Ohio'\n",
      " 'Georgia' 'Arizona' 'Wyoming' 'Delaware' 'Kentucky' 'Kansas' 'ohio'\n",
      " 'Colorado' 'North Carolina' 'New Mexico' 'Illinois ' 'Alaska'\n",
      " 'South Carolina' 'Minnesota' 'Tennessee' 'Pennsylvania' 'Iowa'\n",
      " 'Connecticut' 'Louisiana' 'Indiana' 'Florida ' 'Utah' 'Michigan'\n",
      " 'Oklahoma' 'Nevada' 'Oregon ' 'Virgina' 'Nebraska' 'Georgia '\n",
      " 'Washington D.C.' 'California ' 'Massachusetts ' 'Alabama' 'Russia'\n",
      " 'Washington state' 'Washington' 'District of Columbia' 'Colorado '\n",
      " 'New Hampshire ' 'Mississippi' 'Rhode island' 'China' 'United Kingdom'\n",
      " 'Virginia ' 'South Dakota' 'Qatar' 'Montana' 'North Dakota' 'Idaho'\n",
      " 'Maine' 'New York ' 'Virginia director, Coalition to Stop Gun Violence'\n",
      " 'Virgiia' 'Hawaii' 'Atlanta' 'Tennesse' 'Washington DC' 'Wisconsin '\n",
      " 'PA - Pennsylvania' 'Tex' 'the United States' 'Rhode Island ']\n",
      "Number of unique states: 83\n"
     ]
    }
   ],
   "source": [
    "# Fill missing state values with 'Unknown'\n",
    "train_df['state'] = train_df['state'].fillna('Unknown')\n",
    "valid_df['state'] = valid_df['state'].fillna('Unknown')\n",
    "test_df['state']  = test_df['state'].fillna('Unknown')\n",
    "\n",
    "# Check unique values for manual inspection\n",
    "print(\"Unique states in train:\", train_df['state'].unique())\n",
    "print(\"Number of unique states:\", len(train_df['state'].unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c7aee9",
   "metadata": {},
   "source": [
    "We filled missing values in the 'state' column with 'Unknown' to retain all rows for modeling. \n",
    "This ensures that missing information is explicitly represented without dropping data. \n",
    "We then print the unique values to manually inspect and standardize inconsistent entries (e.g., typos, extra spaces, duplicate names) before encoding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dab928",
   "metadata": {},
   "source": [
    "We cleaned and standardized the 'state' column to remove duplicates, fix typos, and handle inconsistent formatting. \n",
    "This ensures that each unique state is represented consistently, preventing unnecessary duplication of one-hot encoded columns \n",
    "and maintaining meaningful categorical features for the model. Non-state entries and missing values were mapped to 'Other' or 'Unknown'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e361dfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique states after cleaning: ['Texas' 'Virginia' 'Illinois' 'Other' 'Florida' 'Wisconsin' 'New Jersey'\n",
      " 'Vermont' 'Massachusetts' 'Maryland' 'Washington D.C.' 'Oregon'\n",
      " 'New York' 'California' 'Missouri' 'Rhode Island' 'West Virginia'\n",
      " 'Arkansas' 'New Hampshire' 'Ohio' 'Georgia' 'Arizona' 'Wyoming'\n",
      " 'Delaware' 'Kentucky' 'Kansas' 'Colorado' 'North Carolina' 'New Mexico'\n",
      " 'Alaska' 'South Carolina' 'Minnesota' 'Tennessee' 'Pennsylvania' 'Iowa'\n",
      " 'Connecticut' 'Louisiana' 'Indiana' 'Utah' 'Michigan' 'Oklahoma' 'Nevada'\n",
      " 'Nebraska' 'Alabama' 'Washington' 'Mississippi' 'South Dakota' 'Montana'\n",
      " 'North Dakota' 'Idaho' 'Maine' 'Hawaii']\n",
      "Number of unique states: 52\n"
     ]
    }
   ],
   "source": [
    "# Updated mapping for cleaning and standardizing state names\n",
    "state_mapping = {\n",
    "    'ohio': 'Ohio',\n",
    "    'Virgina': 'Virginia',\n",
    "    'Virgiia': 'Virginia',\n",
    "    'Virginia ': 'Virginia',\n",
    "    'Tex': 'Texas',\n",
    "    'Florida ': 'Florida',\n",
    "    'Massachusetts ': 'Massachusetts',\n",
    "    'Illinois ': 'Illinois',\n",
    "    'Rhode island': 'Rhode Island',\n",
    "    'Rhode Island ': 'Rhode Island',\n",
    "    'Washington, D.C.': 'Washington D.C.',\n",
    "    'Washington, D.C. ': 'Washington D.C.',\n",
    "    'Washington D.C.': 'Washington D.C.',\n",
    "    'Washington DC': 'Washington D.C.',\n",
    "    'District of Columbia': 'Washington D.C.',\n",
    "    'Washington state': 'Washington',\n",
    "    'PA - Pennsylvania': 'Pennsylvania',\n",
    "    'Atlanta': 'Other',\n",
    "    'Russia': 'Other',\n",
    "    'China': 'Other',\n",
    "    'United Kingdom': 'Other',\n",
    "    'the United States': 'Other',\n",
    "    'New Hampshire ': 'New Hampshire',\n",
    "    'California ': 'California',\n",
    "    'Wisconsin ': 'Wisconsin',\n",
    "    'Unknown': 'Other',\n",
    "    'Oregon ': 'Oregon',\n",
    "    'Georgia ': 'Georgia',\n",
    "    'New York ': 'New York',\n",
    "    'Colorado ': 'Colorado',\n",
    "    'Qatar': 'Other',\n",
    "    'Virginia director, Coalition to Stop Gun Violence': 'Virginia',\n",
    "    'Tennesse': 'Tennessee'\n",
    "}\n",
    "\n",
    "# Apply mapping and fill remaining NaNs with 'Other'\n",
    "for df in [train_df, valid_df, test_df]:\n",
    "    df['state'] = df['state'].replace(state_mapping).fillna('Other')\n",
    "\n",
    "# Display unique states after cleaning\n",
    "print(\"Unique states after cleaning:\", train_df['state'].unique())\n",
    "print(\"Number of unique states:\", len(train_df['state'].unique()))\n",
    "\n",
    "# One-hot encode\n",
    "train_df = pd.get_dummies(train_df, columns=['state'], prefix='state')\n",
    "valid_df = pd.get_dummies(valid_df, columns=['state'], prefix='state')\n",
    "test_df  = pd.get_dummies(test_df,  columns=['state'], prefix='state')\n",
    "\n",
    "# Align columns so train/valid/test all have same structure\n",
    "train_df, valid_df = train_df.align(valid_df, join='left', axis=1, fill_value=0)\n",
    "train_df, test_df  = train_df.align(test_df,  join='left', axis=1, fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "064a12be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original 'state' column if it still exists\n",
    "for df in [train_df, valid_df, test_df]:\n",
    "    if 'state' in df.columns:\n",
    "        df.drop(columns=['state'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f73f88e",
   "metadata": {},
   "source": [
    "### Drop 'job_title' column\n",
    "We are dropping the 'job_title' column because it has very high cardinality, many missing values, and sparse unique entries. \n",
    "Encoding it (via one-hot, frequency, or label encoding) would either create too many columns or introduce noise. \n",
    "Other features like 'statement', 'state', and 'party' already provide strong information for the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2b097569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'job_title' from train, valid, and test datasets\n",
    "train_df = train_df.drop(columns=['job_title'])\n",
    "valid_df = valid_df.drop(columns=['job_title'])\n",
    "test_df  = test_df.drop(columns=['job_title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d20afb",
   "metadata": {},
   "source": [
    "##### Basic text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4693ea8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>statement_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>says annies list political group supports thir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>decline coal start started natural gas took st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>hillary clinton agrees john mccain voting give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>health care reform legislation likely mandate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>economic turnaround started end term</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           statement  \\\n",
       "0  Says the Annies List political group supports ...   \n",
       "1  When did the decline of coal start? It started...   \n",
       "2  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3  Health care reform legislation is likely to ma...   \n",
       "4  The economic turnaround started at the end of ...   \n",
       "\n",
       "                                     statement_clean  \n",
       "0  says annies list political group supports thir...  \n",
       "1  decline coal start started natural gas took st...  \n",
       "2  hillary clinton agrees john mccain voting give...  \n",
       "3  health care reform legislation likely mandate ...  \n",
       "4               economic turnaround started end term  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation, numbers, special characters\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # Remove stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "# Apply to train, valid, and test\n",
    "train_df['statement_clean'] = train_df['statement'].apply(clean_text)\n",
    "valid_df['statement_clean'] = valid_df['statement'].apply(clean_text)\n",
    "test_df['statement_clean']  = test_df['statement'].apply(clean_text)\n",
    "\n",
    "# Preview\n",
    "train_df[['statement', 'statement_clean']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2704ce",
   "metadata": {},
   "source": [
    "##### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a073ab7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple whitespace tokenization\n",
    "train_df['tokens'] = train_df['statement_clean'].apply(lambda x: x.split())\n",
    "valid_df['tokens'] = valid_df['statement_clean'].apply(lambda x: x.split())\n",
    "test_df['tokens']  = test_df['statement_clean'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "15e89142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement_clean</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>says annies list political group supports thir...</td>\n",
       "      <td>[says, annies, list, political, group, support...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>decline coal start started natural gas took st...</td>\n",
       "      <td>[decline, coal, start, started, natural, gas, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hillary clinton agrees john mccain voting give...</td>\n",
       "      <td>[hillary, clinton, agrees, john, mccain, votin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>health care reform legislation likely mandate ...</td>\n",
       "      <td>[health, care, reform, legislation, likely, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>economic turnaround started end term</td>\n",
       "      <td>[economic, turnaround, started, end, term]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     statement_clean  \\\n",
       "0  says annies list political group supports thir...   \n",
       "1  decline coal start started natural gas took st...   \n",
       "2  hillary clinton agrees john mccain voting give...   \n",
       "3  health care reform legislation likely mandate ...   \n",
       "4               economic turnaround started end term   \n",
       "\n",
       "                                              tokens  \n",
       "0  [says, annies, list, political, group, support...  \n",
       "1  [decline, coal, start, started, natural, gas, ...  \n",
       "2  [hillary, clinton, agrees, john, mccain, votin...  \n",
       "3  [health, care, reform, legislation, likely, ma...  \n",
       "4         [economic, turnaround, started, end, term]  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview\n",
    "train_df[['statement_clean', 'tokens']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a41b72",
   "metadata": {},
   "source": [
    "#### Normalizing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b265caf",
   "metadata": {},
   "source": [
    "##### Lemmatization of Tokens\n",
    "- We use **lemmatization** instead of stemming because it preserves the actual dictionary form of words, maintaining their meaning. This is crucial for Fake News detection, where subtle differences in word meaning can affect the model's understanding.  \n",
    "- Stemming, on the other hand, produces non-words and may reduce the quality of features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e451dee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[says, annies, list, political, group, support...</td>\n",
       "      <td>[say, annies, list, political, group, support,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[decline, coal, start, started, natural, gas, ...</td>\n",
       "      <td>[decline, coal, start, started, natural, gas, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[hillary, clinton, agrees, john, mccain, votin...</td>\n",
       "      <td>[hillary, clinton, agrees, john, mccain, votin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[health, care, reform, legislation, likely, ma...</td>\n",
       "      <td>[health, care, reform, legislation, likely, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[economic, turnaround, started, end, term]</td>\n",
       "      <td>[economic, turnaround, started, end, term]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [says, annies, list, political, group, support...   \n",
       "1  [decline, coal, start, started, natural, gas, ...   \n",
       "2  [hillary, clinton, agrees, john, mccain, votin...   \n",
       "3  [health, care, reform, legislation, likely, ma...   \n",
       "4         [economic, turnaround, started, end, term]   \n",
       "\n",
       "                                          tokens_lem  \n",
       "0  [say, annies, list, political, group, support,...  \n",
       "1  [decline, coal, start, started, natural, gas, ...  \n",
       "2  [hillary, clinton, agrees, john, mccain, votin...  \n",
       "3  [health, care, reform, legislation, likely, ma...  \n",
       "4         [economic, turnaround, started, end, term]  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Apply lemmatization to tokens\n",
    "def lemmatize_tokens(tokens):\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "train_df['tokens_lem'] = train_df['tokens'].apply(lemmatize_tokens)\n",
    "valid_df['tokens_lem'] = valid_df['tokens'].apply(lemmatize_tokens)\n",
    "test_df['tokens_lem']  = test_df['tokens'].apply(lemmatize_tokens)\n",
    "\n",
    "# Preview\n",
    "train_df[['tokens', 'tokens_lem']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f0251a",
   "metadata": {},
   "source": [
    "#### Feature extraction / Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873aea4e",
   "metadata": {},
   "source": [
    "##### TF-IDF Vectorization\n",
    "We use **TF-IDF (Term Frequencyâ€“Inverse Document Frequency)** to convert the lemmatized tokens into numeric features.  \n",
    "\n",
    "**Why TF-IDF?**  \n",
    "- Highlights words that are **important and distinctive** for each statement.  \n",
    "- Reduces the influence of very common words that appear in almost all statements.  \n",
    "- Typically performs better than simple Bag-of-Words for text classification tasks like Fake News detection.  \n",
    "\n",
    "**Why not Bag-of-Words?**  \n",
    "- Bag-of-Words treats all words equally, giving too much weight to frequent but uninformative words.  \n",
    "- TF-IDF focuses on words that help the model differentiate between classes.\n",
    "\n",
    "**Why not Embeddings (Word2Vec, GloVe, BERT, etc.)?**  \n",
    "- Embeddings capture semantic meaning, which is powerful but more complex to implement.  \n",
    "- They require more computational resources and a more advanced model architecture (e.g., deep learning).  \n",
    "- For a **first baseline model**, TF-IDF is simpler, faster, and easier to use with classical ML classifiers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "420da6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train features: (10238, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Join lemmatized tokens back into a single string for vectorizer\n",
    "train_texts = train_df['tokens_lem'].apply(lambda x: ' '.join(x))\n",
    "valid_texts = valid_df['tokens_lem'].apply(lambda x: ' '.join(x))\n",
    "test_texts  = test_df['tokens_lem'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Initialize TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=10000)  # limit vocabulary size for efficiency\n",
    "\n",
    "# Fit on train and transform train, valid, test\n",
    "X_train = tfidf.fit_transform(train_texts)\n",
    "X_valid = tfidf.transform(valid_texts)\n",
    "X_test  = tfidf.transform(test_texts)\n",
    "\n",
    "# Target labels\n",
    "y_train = train_df['label']\n",
    "y_valid = valid_df['label']\n",
    "y_test  = test_df['label']\n",
    "\n",
    "print(\"Shape of train features:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7309f378",
   "metadata": {},
   "source": [
    "### Feature Engineering and Combination\n",
    "\n",
    "We transformed and combined all features as follows:\n",
    "\n",
    "1. **Statement (`statement`)**  \n",
    "   - Preprocessed using tokenization, stopword removal, and lemmatization.  \n",
    "   - Converted into a **TF-IDF vector** (`X_train`, `X_valid`, `X_test`) with a maximum vocabulary of 5000.  \n",
    "\n",
    "2. **Subject (`subject`)**  \n",
    "   - Filled missing values with empty strings.  \n",
    "   - Converted into a **TF-IDF vector** (`X_train_subject`, `X_valid_subject`, `X_test_subject`) with a maximum of 500 features.  \n",
    "\n",
    "3. **Speaker (`speaker`)**  \n",
    "   - Encoded by **frequency mapping** (number of times the speaker appears in the training set).  \n",
    "\n",
    "4. **Party (`party`)**  \n",
    "   - One-hot encoded to represent each category as a binary feature.  \n",
    "\n",
    "5. **State (`state`)**  \n",
    "   - Cleaned and mapped inconsistent state names.  \n",
    "   - One-hot encoded after filling missing values with `'Other'`.  \n",
    "\n",
    "6. **Numerical features**  \n",
    "   - Included counts for `barely_true`, `false`, `half_true`, `mostly_true`, and `pants_fire`.  \n",
    "\n",
    "7. **Dropping unnecessary columns**  \n",
    "   - Removed `id`, `context`, `job_title`, `statement_clean`, `tokens`, `tokens_lem` from the feature matrix.  \n",
    "\n",
    "8. **Combining all features**  \n",
    "   - Converted all numeric and one-hot features to **sparse matrices**.  \n",
    "   - Horizontally stacked **statement TF-IDF**, **subject TF-IDF**, and **numeric/OHE features** using `scipy.sparse.hstack` to create the final matrices:  \n",
    "     - `X_train_all`  \n",
    "     - `X_valid_all`  \n",
    "     - `X_test_all`  \n",
    "\n",
    "This approach ensures all text, categorical, and numerical features are properly represented in a single high-dimensional sparse matrix, ready for modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fb6ccd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of combined train features: (10238, 10208)\n",
      "Shape of combined valid features: (1284, 10216)\n",
      "Shape of combined test features: (1267, 10217)\n"
     ]
    }
   ],
   "source": [
    "# --------- Prepare numeric / one-hot features ----------\n",
    "# Drop text columns that can't go into sparse matrix\n",
    "drop_cols = ['statement', 'statement_clean', 'tokens', 'tokens_lem']\n",
    "\n",
    "# Select numeric/OHE columns only\n",
    "train_cat_num = train_df.drop(columns=drop_cols, errors='ignore').select_dtypes(include=[np.number])\n",
    "valid_cat_num = valid_df.drop(columns=drop_cols, errors='ignore').select_dtypes(include=[np.number])\n",
    "test_cat_num  = test_df.drop(columns=drop_cols, errors='ignore').select_dtypes(include=[np.number])\n",
    "\n",
    "# Convert to sparse\n",
    "X_train_cat = csr_matrix(train_cat_num.values)\n",
    "X_valid_cat = csr_matrix(valid_cat_num.values)\n",
    "X_test_cat  = csr_matrix(test_cat_num.values)\n",
    "\n",
    "# --------- Combine all features ----------\n",
    "X_train_all = hstack([X_train, X_train_subject, X_train_cat])\n",
    "X_valid_all = hstack([X_valid, X_valid_subject, X_valid_cat])\n",
    "X_test_all  = hstack([X_test, X_test_subject, X_test_cat])\n",
    "\n",
    "print(\"Shape of combined train features:\", X_train_all.shape)\n",
    "print(\"Shape of combined valid features:\", X_valid_all.shape)\n",
    "print(\"Shape of combined test features:\", X_test_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "18aa3666",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['label']\n",
    "y_valid = valid_df['label']\n",
    "y_test  = test_df['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c7d55924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of combined train features: (10238, 10208)\n",
      "Shape of combined valid features: (1284, 10216)\n",
      "Shape of combined test features: (1267, 10217)\n",
      "Aligned shapes:\n",
      "Train: (10238, 10208)\n",
      "Valid: (1284, 10208)\n",
      "Test:  (1267, 10208)\n"
     ]
    }
   ],
   "source": [
    "# --------- Combine all features ----------\n",
    "X_train_all = hstack([X_train, X_train_subject, X_train_cat])\n",
    "X_valid_all = hstack([X_valid, X_valid_subject, X_valid_cat])\n",
    "X_test_all  = hstack([X_test, X_test_subject, X_test_cat])\n",
    "\n",
    "print(\"Shape of combined train features:\", X_train_all.shape)\n",
    "print(\"Shape of combined valid features:\", X_valid_all.shape)\n",
    "print(\"Shape of combined test features:\", X_test_all.shape)\n",
    "\n",
    "# --------- Align validation and test with train ----------\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "def align_features(X_train, X_other):\n",
    "    X_train = csr_matrix(X_train)\n",
    "    X_other = csr_matrix(X_other)\n",
    "    \n",
    "    n_train = X_train.shape[1]\n",
    "    n_other = X_other.shape[1]\n",
    "    \n",
    "    if n_other < n_train:\n",
    "        extra_cols = csr_matrix(np.zeros((X_other.shape[0], n_train - n_other)))\n",
    "        X_other = hstack([X_other, extra_cols])\n",
    "    elif n_other > n_train:\n",
    "        X_other = X_other[:, :n_train]\n",
    "    \n",
    "    return X_other\n",
    "\n",
    "X_valid_all = align_features(X_train_all, X_valid_all)\n",
    "X_test_all  = align_features(X_train_all, X_test_all)\n",
    "\n",
    "print(\"Aligned shapes:\")\n",
    "print(\"Train:\", X_train_all.shape)\n",
    "print(\"Valid:\", X_valid_all.shape)\n",
    "print(\"Test: \", X_test_all.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25440317",
   "metadata": {},
   "source": [
    "## Model Suitability for High-Dimensional, Text-Heavy Sparse Data\n",
    "\n",
    "| Model Type                  | Suitability        | Reason / Notes                                                                 |\n",
    "|------------------------------|-----------------|-------------------------------------------------------------------------------|\n",
    "| **Multinomial/Bernoulli Naive Bayes** | Best             | Naturally handles high-dimensional sparse features (TF-IDF). Very fast.       |\n",
    "| **Logistic Regression (L1/L2)**       | Best             | Efficient with sparse data. Regularization helps prevent overfitting.        |\n",
    "| **LinearSVC (SVM)**                     | Best             | Works well with high-dimensional sparse text. Effective for classification.  |\n",
    "| **SGDClassifier (Linear)**              | Best             | Handles large sparse datasets efficiently.                                     |\n",
    "| **Random Forest**                        | Good             | Handles mixed features, but slow and memory-intensive on high-dimensional sparse data. |\n",
    "| **XGBoost / LightGBM**                   | Good             | Can handle numerical + OHE features. Performs well but slower with sparse TF-IDF. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3231925f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MultinomialNB...\n",
      "MultinomialNB Validation Accuracy: 0.3045\n",
      "\n",
      "Training LogisticRegression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\37789\\OneDrive\\Documents\\GitHub\\VeracityCheck-Fake_News_Classifier\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Validation Accuracy: 0.9229\n",
      "\n",
      "Training LinearSVC...\n",
      "LinearSVC Validation Accuracy: 0.6184\n",
      "\n",
      "Training SGDClassifier...\n",
      "SGDClassifier Validation Accuracy: 0.6012\n",
      "\n",
      "Training RandomForest...\n",
      "RandomForest Validation Accuracy: 0.8808\n",
      "\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\37789\\OneDrive\\Documents\\GitHub\\VeracityCheck-Fake_News_Classifier\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:01:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Validation Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store models and results\n",
    "models = {\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000),\n",
    "    \"LinearSVC\": LinearSVC(max_iter=5000),\n",
    "    \"SGDClassifier\": SGDClassifier(max_iter=5000),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "}\n",
    "\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # For RF and XGB, convert sparse to dense\n",
    "    if name in [\"RandomForest\", \"XGBoost\"]:\n",
    "        X_train_model = X_train_all.toarray()\n",
    "        X_valid_model = X_valid_all.toarray()\n",
    "    else:\n",
    "        X_train_model = X_train_all\n",
    "        X_valid_model = X_valid_all\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_train_model, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_valid_model)\n",
    "    \n",
    "    # Evaluate\n",
    "    acc = accuracy_score(y_valid, y_pred)\n",
    "    print(f\"{name} Validation Accuracy: {acc:.4f}\")\n",
    "    \n",
    "    results[name] = acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3ac771",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
